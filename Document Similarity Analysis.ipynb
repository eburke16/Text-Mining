{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I authored this code as part of an assignment for the master's level Python course I took at Columbia University. \n",
    "\n",
    "### This example uses Wikipedia’s List of Ancient Greek Philosophers to compare philosophers' biographies and identify which philosopher is most similar to each other.  The link to the original page can be found here: \n",
    "#### https://en.wikipedia.org/wiki/List_of_ancient_Greek_philosophers\n",
    "\n",
    "### My code is broken down into three parts:\n",
    "\n",
    "- First, I scrape philosophers' biographies from their Wikipedia page and construct a corpus of documents. \n",
    "- Next, I created a function that gets the content from an article given only its file path.\n",
    "- Finally, I build the LSI model to match every philosopher to its most similar one based on their Wikipedia biographies.\n",
    " \n",
    " \n",
    "### Skills used: \n",
    "- Web Scraping\n",
    "- LSI/LSA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs, loading libraries and necessary methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import _sqlite3\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import sent_tokenize,word_tokenize \n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.similarities.docsim import Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "\n",
    "### Write a function that takes the file name of the Wikipedia page containing all Ancient Greek Philosophers (saved as \"Index.html\" in my workspace) and returns a list tuples containing the name of the philosopher and the path to its individual article file.\n",
    "\n",
    "### Expected output: A list of tuples containing the name of the Greek God and the link to their biography. \n",
    "[('Acrion', 'Philosophers/Acrion.html'),\n",
    " ('Adrastus of Aphrodisias', 'Philosophers/Adrastus of Aphrodisias.html'),\n",
    " ('Aedesia', 'Philosophers/Aedesia.html'),\n",
    " ('Aedesius', 'Philosophers/Aedesius.html'),\n",
    " ('Aeneas of Gaza', 'Philosophers/Aeneas of Gaza.html'),\n",
    " ('Aenesidemus', 'Philosophers/Aenesidemus.html'),\n",
    " ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_philosophers(filename):\n",
    "\n",
    "    f = codecs.open(filename, 'r', 'utf-8')\n",
    "    soup = BeautifulSoup(f.read(),'lxml')\n",
    "        \n",
    "    filenames = list()     \n",
    "    table_body=soup.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        try:\n",
    "            philosopher_name=row.find('a').get('title')\n",
    "            print(philosopher_name)\n",
    "            philosopher_link = \"Philosophers/\" + philosopher_name + \".html\"\n",
    "            filenames.append((philosopher_name,philosopher_link))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return filenames\n",
    "                        \n",
    "    ###\n",
    "    \n",
    "# Once done, try this:\n",
    "filenames = get_philosophers(\"philosophers.html\")\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "\n",
    "### This section scrapes the text on a philosophers’s page and returns it as a text string. The input is the name of the file that contains the philosoph's page.\n",
    "\n",
    "### For example: \n",
    "get_text('Philosophers/Acrion.html') will output the text of the page.\n",
    "'Acrion was a Locrian and a Pythagorean philosopher...'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(file):  \n",
    "    f = codecs.open(file, 'r', 'utf-8')\n",
    "    soup = BeautifulSoup(f.read(),'lxml')\n",
    "    all_text = \"\"\n",
    "\n",
    "    for tag in soup.find_all('p'):\n",
    "        all_text += tag.get_text() \n",
    "    return all_text    \n",
    "\n",
    "\n",
    "# Once done, try this:\n",
    "get_text(\"Philosophers/Agathobulus.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three\n",
    "\n",
    "### This section uses the files found in the \"Philosophers\" folder to construct an LSA model.  The LSA model is then used to find the most similar philosopher for each of the philosophers found in Part One, based on the content of their Wikipedia articles. \n",
    "\n",
    "Note: In this section, I do not go online to scrape the data; everything needed is in this Jupyter notebook working directory.\n",
    "\n",
    "The function takes an the list of tuples created in Part One as the input.\n",
    "\n",
    "The output is also a list of tuples. Each tuple contains a philosopher's name and its most similar other philosopher. Please note both names will not be the same.\n",
    "\n",
    "#### The output looks like:\n",
    "\n",
    "[('Acrion', 'Athenodoros Cananites'),\n",
    "\n",
    " ('Adrastus of Aphrodisias', 'Andronicus of Rhodes'),\n",
    " \n",
    " ('Aedesia', 'Ammonius of Athens'),\n",
    " \n",
    " ('Aedesius', 'Arete of Cyrene'),\n",
    " \n",
    " ('Aeneas of Gaza', 'Ammonius Hermiae'),\n",
    " \n",
    " ...]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(filenames):\n",
    "\n",
    "    from collections import defaultdict\n",
    "    from gensim import models\n",
    "    \n",
    "    philosophers_texts=[]\n",
    "    most_similar=[]\n",
    "    documents=[]\n",
    "    \n",
    "    for x in range(len(filenames)):\n",
    "        philosophers_text = get_text(filenames[x][1])\n",
    "        philosophers_text = philosophers_text.replace('\\n\\n', ' ')\n",
    "        philosophers_text = philosophers_text.replace('\\n', ' ')\n",
    "        documents.append(philosophers_text)\n",
    "    \n",
    "    stoplist = set('for a of the and to in'.split())\n",
    "    texts = [\n",
    "        [word for word in document.lower().split() if word not in STOPWORDS and word not in stoplist and word.isalnum()]\n",
    "        for document in documents\n",
    "    ]\n",
    "\n",
    "    dictionary = corpora.Dictionary(texts) \n",
    "    corpus = [dictionary.doc2bow(text) for text in texts] \n",
    "\n",
    "    lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=10)\n",
    "    \n",
    "    for x in range(len(filenames)):\n",
    "        doc = get_text(filenames[x][1])\n",
    "        doc = doc.replace('\\n\\n', ' ')\n",
    "        doc = doc.replace('\\n', ' ')\n",
    "\n",
    "        vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "        vec_lsi = lsi[vec_bow]  \n",
    "        \n",
    "        index = similarities.MatrixSimilarity(lsi[corpus])  \n",
    "        sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
    "        sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "        most_similar.append((filenames[x][0], filenames[sims[1][0]][0]))\n",
    "        \n",
    "    return most_similar\n",
    "\n",
    "###\n",
    "\n",
    "# Once done, try this:\n",
    "run(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
